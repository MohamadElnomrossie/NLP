{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(text,N, start_tags=True,end_tags=True):\n",
    "    '''This function returns Ngrams words from a given text\n",
    "    inputs:\n",
    "    Text: the text to be analyzed\n",
    "    N: number of grams\n",
    "    Start_tag ,bool, if set to true it adds the number of\n",
    "    N-1 {<s>} start tags to the beginning of the sentence\n",
    "    to the beginning of the sentence to match.\n",
    "    end_tags=True ,bool, if set to True, it adds{</s} end of\n",
    "    sentence tag to the end of the sentence\n",
    "    \n",
    "    outputs:\n",
    "    a dictionary mapping the original sentence to the ngrams'''\n",
    "    t=sent_tokenize(text)\n",
    "    ngrams={}\n",
    "    for sent in t:\n",
    "        ngrams[sent]=[]\n",
    "        tok_sent=word_tokenize(sent)\n",
    "        if start_tags and end_tags:\n",
    "            tok_sent=['<s>']*(N-1)+tok_sent+['</s>']\n",
    "        elif start_tags==True and end_tags==False:\n",
    "            tok_sent=['<s>']*(N-1)+tok_sent\n",
    "        elif start_tags==False and end_tags==True:\n",
    "            tok_sent=tok_sent+['</s>']\n",
    "        for i in range(len(tok_sent)-N+1):\n",
    "            ngrams[sent].append(tok_sent[i:i+N])\n",
    "    return ngrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
